import streamlit as st
import tensorflow as tf
import cv2
import numpy as np
from tensorflow.keras.applications.efficientnet import preprocess_input 

# ==========================================
# 1. T·ª™ ƒêI·ªÇN Y KHOA
# ==========================================
medical_info = {
    "Glioma": {
        "description": "U th·∫ßn kinh ƒë·ªám (Glioma) l√† lo·∫°i u n√£o ph·ªï bi·∫øn nh·∫•t b·∫Øt ngu·ªìn t·ª´ c√°c t·∫ø b√†o th·∫ßn kinh ƒë·ªám. Kh·ªëi u th∆∞·ªùng c√≥ t√≠nh ch·∫•t x√¢m l·∫•n.",
        "risk": "‚ö†Ô∏è M·ª©c ƒë·ªô: C·∫ßn ch√∫ √Ω cao (Th∆∞·ªùng √°c t√≠nh)",
        "recommendation": "ƒê·ªÅ xu·∫•t: C·∫ßn ch·ª•p MRI c√≥ thu·ªëc c·∫£n quang ƒë·ªÉ x√°c ƒë·ªãnh ranh gi·ªõi u. H·ªôi ch·∫©n ph·∫´u thu·∫≠t ho·∫∑c x·∫° tr·ªã t√πy v·ªã tr√≠."
    },
    "Meningioma": {
        "description": "U m√†ng n√£o (Meningioma) xu·∫•t ph√°t t·ª´ m√†ng nh·ªán bao quanh n√£o. ƒêa s·ªë l√† l√†nh t√≠nh v√† ph√°t tri·ªÉn ch·∫≠m.",
        "risk": "‚ÑπÔ∏è M·ª©c ƒë·ªô: Th∆∞·ªùng l√†nh t√≠nh",
        "recommendation": "ƒê·ªÅ xu·∫•t: Theo d√µi ƒë·ªãnh k·ª≥ n·∫øu u nh·ªè. Ph·∫´u thu·∫≠t c·∫Øt b·ªè n·∫øu u g√¢y ch√®n √©p th·∫ßn kinh."
    },
    "Pituitary": {
        "description": "U tuy·∫øn y√™n (Pituitary Tumor) n·∫±m ·ªü h·ªë y√™n, c√≥ th·ªÉ g√¢y r·ªëi lo·∫°n n·ªôi ti·∫øt ho·∫∑c ch√®n √©p giao thoa th·ªã gi√°c.",
        "risk": "‚ÑπÔ∏è M·ª©c ƒë·ªô: Th∆∞·ªùng l√†nh t√≠nh nh∆∞ng ·∫£nh h∆∞·ªüng ch·ª©c nƒÉng",
        "recommendation": "ƒê·ªÅ xu·∫•t: X√©t nghi·ªám hormone, ki·ªÉm tra th·ªã tr∆∞·ªùng m·∫Øt. ƒêi·ªÅu tr·ªã n·ªôi khoa ho·∫∑c ph·∫´u thu·∫≠t qua xoang b∆∞·ªõm."
    },
    "No Tumor": {
        "description": "Kh√¥ng ph√°t hi·ªán kh·ªëi u b·∫•t th∆∞·ªùng r√µ r·ªát tr√™n h√¨nh ·∫£nh MRI n√†y.",
        "risk": "‚úÖ M·ª©c ƒë·ªô: B√¨nh th∆∞·ªùng",
        "recommendation": "ƒê·ªÅ xu·∫•t: Duy tr√¨ l·ªëi s·ªëng l√†nh m·∫°nh. N·∫øu v·∫´n c√≥ tri·ªáu ch·ª©ng ƒëau ƒë·∫ßu, h√£y kh√°m chuy√™n khoa th·∫ßn kinh."
    }
}

# ==========================================
# 2. C√ÅC H√ÄM X·ª¨ L√ù (CORE)
# ==========================================

def crop_brain_contour(image, plot=False):
    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    gray = cv2.GaussianBlur(gray, (5, 5), 0)
    
    thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]
    thresh = cv2.erode(thresh, None, iterations=2)
    thresh = cv2.dilate(thresh, None, iterations=2)
    
    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    cnts = cnts[0] if len(cnts) == 2 else cnts[1]
    
    if len(cnts) > 0:
        c = max(cnts, key=cv2.contourArea)
        x, y, w, h = cv2.boundingRect(c)
        new_image = image[y:y+h, x:x+w]
        return new_image
    return image

def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):
    grad_model = tf.keras.models.Model(
        model.inputs, [model.get_layer(last_conv_layer_name).output, model.output]
    )

    with tf.GradientTape() as tape:
        last_conv_layer_output, preds = grad_model(img_array)
        if isinstance(preds, list): preds = preds[0]
        preds = tf.convert_to_tensor(preds)
        
        if pred_index is None:
            pred_index = tf.argmax(preds[0])
        class_channel = preds[:, pred_index]

    grads = tape.gradient(class_channel, last_conv_layer_output)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
    last_conv_layer_output = last_conv_layer_output[0]
    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
    heatmap = tf.squeeze(heatmap)
    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
    
    # L∆ØU √ù: ƒê√£ b·ªè ph·∫ßn che vi·ªÅn ƒëen (Spatial Masking) ƒë·ªÉ b·∫Øt ƒë∆∞·ª£c u s√°t s·ªç
    return heatmap.numpy()

def draw_bbox_from_heatmap(image, heatmap, threshold=0.5):
    # Nh·ªã ph√¢n h√≥a Heatmap: Ch·ªâ l·∫•y v√πng "n√≥ng" tr√™n 50%
    heatmap_resized = cv2.resize(heatmap, (image.shape[1], image.shape[0]))
    heatmap_uint8 = np.uint8(255 * heatmap_resized)
    
    _, thresh = cv2.threshold(heatmap_uint8, int(255 * threshold), 255, cv2.THRESH_BINARY)
    
    cnts = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    cnts = cnts[0] if len(cnts) == 2 else cnts[1]
    
    output_image = image.copy()
    
    if len(cnts) > 0:
        c = max(cnts, key=cv2.contourArea)
        x, y, w, h = cv2.boundingRect(c)
        # V·∫Ω khung xanh l√°
        cv2.rectangle(output_image, (x, y), (x + w, y + h), (0, 255, 0), 2)
        cv2.putText(output_image, "Tumor Region", (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
        
    return output_image

# ==========================================
# 3. GIAO DI·ªÜN WEB
# ==========================================
st.set_page_config(page_title="Ch·∫©n ƒêo√°n U N√£o AI Pro", layout="wide")
st.title("üß† H·ªá Th·ªëng Ph√¢n T√≠ch MRI N√£o (EfficientNetB0)")

@st.cache_resource
def load_model():
    model = tf.keras.models.load_model('model.h5')
    return model

try:
    model = load_model()
    st.toast("ƒê√£ t·∫£i m√¥ h√¨nh th√†nh c√¥ng!", icon="‚úÖ")
except Exception as e:
    st.error(f"L·ªói t·∫£i m√¥ h√¨nh: {e}")

uploaded_file = st.file_uploader("Ch·ªçn ·∫£nh MRI...", type=["jpg", "png", "jpeg"])

if uploaded_file is not None:
    file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
    image = cv2.imdecode(file_bytes, 1)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.info("1. ·∫¢nh G·ªëc")
        st.image(image, use_column_width=True)

    # X·ª≠ l√Ω
    cropped_image = crop_brain_contour(image)
    IMG_SIZE = 224 
    resized_image = cv2.resize(cropped_image, (IMG_SIZE, IMG_SIZE))
    input_arr = np.array(resized_image, dtype=np.float32)
    processed_image = preprocess_input(input_arr) 
    input_data = np.expand_dims(processed_image, axis=0)

    with col2:
        st.warning(f"2. Input Model ({IMG_SIZE}x{IMG_SIZE})")
        st.image(resized_image, use_column_width=True)

    if st.button("Ch·∫°y Ch·∫©n ƒêo√°n"):
        try:
            # D·ª± ƒëo√°n
            prediction = model.predict(input_data)
            labels = ['Glioma', 'Meningioma', 'No Tumor', 'Pituitary']
            
            pred_index = np.argmax(prediction)
            predicted_class = labels[pred_index]
            confidence = np.max(prediction) * 100
            
            st.divider()
            
            # Grad-CAM & Bounding Box
            last_conv_layer_name = "top_activation"
            heatmap = make_gradcam_heatmap(input_data, model, last_conv_layer_name)
            
            # V·∫Ω khung (V·ªõi ƒë·ªô nh·∫°y 0.5)
            bbox_img = draw_bbox_from_heatmap(cropped_image, heatmap, threshold=0.5)
            
            with col3:
                st.success("3. ƒê·ªãnh v·ªã Kh·ªëi u")
                st.image(bbox_img, use_column_width=True)
                st.caption(f"K·∫øt qu·∫£: {predicted_class} ({confidence:.2f}%)")
            
            # Hi·ªÉn th·ªã th√¥ng tin y khoa
            info = medical_info[predicted_class]
            st.write("---")
            st.subheader(f"üìã H·ªì s∆°: {predicted_class}")
            
            c1, c2 = st.columns([1, 2])
            with c1:
                st.metric(label="R·ªßi ro", value=predicted_class, delta=info["risk"])
            with c2:
                st.info(f"**M√¥ t·∫£:** {info['description']}")
                st.warning(f"**Khuy·∫øn ngh·ªã:** {info['recommendation']}")
                
        except Exception as e:
            st.error(f"L·ªói: {e}")
